{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(all_gpus=False, batch_size=32, bidirectional=True, continue_from=None, cuda=True, data_name='./data_dvae/bench_102_num', data_type='ENAS', epochs=100, hs=501, infer_batch_size=32, keep_old=False, load_latest_model=False, lr=0.0001, model='DVAE', no_cuda=False, no_test=False, nvt=5, nz=30, only_test=False, predictor=False, reprocess=False, sample_number=20, save_appendix='', save_interval=100, seed=1, small_train=False)\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, glob, random, argparse\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "sys.path.append(str('/home/jiahzhao/Data/NAS-Projects-master/lib'))\n",
    "sys.path.append(str('/home/jiahzhao/Data/NAS-Projects-master/configs'))\n",
    "from config_utils import load_config, dict2config, configure2str\n",
    "from datasets     import get_datasets, SearchDataset\n",
    "from procedures   import prepare_seed, prepare_logger, save_checkpoint, copy_checkpoint, get_optim_scheduler\n",
    "from utils        import get_model_infos, obtain_accuracy\n",
    "from log_utils    import AverageMeter, time_string, convert_secs2time\n",
    "from models       import get_cell_based_tiny_net, get_search_spaces\n",
    "from nas_102_api  import NASBench102API as API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1023it [00:00, 8545.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(all_gpus=True, arch_learning_rate=0.0003, arch_nas_dataset='/home/jiahzhao/Data/NAS-Projects-master/NAS-Bench-102-v1_0-e61699.pth', arch_weight_decay=0.001, batch_size=32, bidirectional=True, channel=16, config_path='/home/jiahzhao/Data/NAS-Projects-master/configs/nas-benchmark/algos/EENAS.config', continue_from=None, cuda=True, data_name='./data_dvae/bench_102_num', data_path='/data/jiahzhao/ENNAS_benchmark102/data/cifar-10-batches-py', data_type='ENAS', dataset='cifar10', epochs=100, hs=501, infer_batch_size=32, keep_old=False, load_latest_model=False, lr=0.0001, max_nodes=4, model='DVAE', no_cuda=False, no_test=False, num_cells=5, nvt=5, nz=30, only_test=False, predictor=False, print_freq=200, rand_seed=0, reprocess=False, sample_number=20, save_appendix='', save_dir='./EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10', save_interval=100, search_space_name='nas-bench-102', seed=1, small_train=False, tau_max=10, tau_min=0.1, track_running_stats=1, workers=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15625it [00:01, 14764.67it/s]\n",
      "100%|██████████| 1563/1563 [00:00<00:00, 1519633.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# node types: 8\n",
      "maximum # nodes: 12\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from shutil import copy\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.linalg import qr \n",
    "import igraph\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from data_dvae.util import *\n",
    "from data_dvae.models_dvae import *\n",
    "import copy\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(\"EENAS_V\")\n",
    "parser.add_argument('--data_path',          type=str,   default= '/data/jiahzhao/ENNAS_benchmark102/data/cifar-10-batches-py', help='Path to dataset')\n",
    "parser.add_argument('--dataset',            type=str,   default= 'cifar10', choices=['cifar10', 'cifar100', 'ImageNet16-120'], help='Choose between Cifar10/100 and ImageNet-16.')\n",
    "# channels and number-of-cells\n",
    "parser.add_argument('--search_space_name',  type=str,   default= 'nas-bench-102',help='The search space name.')\n",
    "parser.add_argument('--max_nodes',          type=int,   default= 4 ,help='The maximum number of nodes.')\n",
    "parser.add_argument('--channel',            type=int,   default= 16,help='The number of channels.')\n",
    "parser.add_argument('--num_cells',          type=int,   default= 5, help='The number of cells in one stage.')\n",
    "parser.add_argument('--track_running_stats',type=int,   default= 1,choices=[0,1],help='Whether use track_running_stats or not in the BN layer.')\n",
    "parser.add_argument('--config_path',        type=str,   default= '/home/jiahzhao/Data/NAS-Projects-master/configs/nas-benchmark/algos/EENAS.config'  ,help='The path of the configuration.')\n",
    "# architecture leraning rate\n",
    "parser.add_argument('--arch_learning_rate', type=float, default=3e-4, help='learning rate for arch encoding')\n",
    "parser.add_argument('--arch_weight_decay',  type=float, default=1e-3, help='weight decay for arch encoding')\n",
    "parser.add_argument('--tau_min',            type=float, default=0.1, help='The minimum tau for Gumbel')\n",
    "parser.add_argument('--tau_max',            type=float, default=10, help='The maximum tau for Gumbel')\n",
    "# log\n",
    "parser.add_argument('--workers',            type=int,   default=2,    help='number of data loading workers (default: 2)')\n",
    "parser.add_argument('--save_dir',           type=str,   default='./EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10',help='Folder to save checkpoints and log.')\n",
    "parser.add_argument('--arch_nas_dataset',   type=str,   default='/home/jiahzhao/Data/NAS-Projects-master/NAS-Bench-102-v1_0-e61699.pth',help='The path to load the architecture dataset (tiny-nas-benchmark).')\n",
    "parser.add_argument('--print_freq',         type=int,   default=200,help='print frequency (default: 200)')\n",
    "parser.add_argument('--rand_seed',          type=int,   default=0, help='manual seed')\n",
    "\n",
    "parser.add_argument('--data-type', default='ENAS',\n",
    "                    help='DARTS: DARTS-format CNN structures; ENAS: ENAS-format CNN structures; BN: Bayesian networks')\n",
    "parser.add_argument('--data-name', default='./data_dvae/bench_102_num', help='graph dataset name')\n",
    "parser.add_argument('--nvt', type=int, default=5, help='number of different node types, \\\n",
    "                    12 for DARTS and 6 for ENAS')\n",
    "parser.add_argument('--save-appendix', default='', \n",
    "                    help='what to append to data-name as save-name for results')\n",
    "parser.add_argument('--save-interval', type=int, default=100, metavar='N',\n",
    "                    help='how many epochs to wait each time to save model states')\n",
    "parser.add_argument('--sample-number', type=int, default=20, metavar='N',\n",
    "                    help='how many samples to generate each time')\n",
    "parser.add_argument('--no-test', action='store_true', default=False,\n",
    "                    help='if True, merge test with train, i.e., no held-out set')\n",
    "parser.add_argument('--reprocess', action='store_true', default=False,\n",
    "                    help='if True, reprocess data instead of using prestored .pkl data')\n",
    "parser.add_argument('--keep-old', action='store_true', default=False,\n",
    "                    help='if True, do not remove any old data in the result folder')\n",
    "parser.add_argument('--only-test', action='store_true', default=False,\n",
    "                    help='if True, perform some experiments without training the model')\n",
    "parser.add_argument('--small-train', action='store_true', default=False,\n",
    "                    help='if True, use a smaller version of train set')\n",
    "# model settings\n",
    "parser.add_argument('--model', default='DVAE', help='model to use: DVAE, SVAE, \\\n",
    "                    DVAE_fast, DVAE_BN, SVAE_oneshot, DVAE_GCN')\n",
    "parser.add_argument('--load-latest-model', action='store_true', default=False,\n",
    "                    help='whether to load latest_model.pth')\n",
    "parser.add_argument('--continue-from', type=int, default=None, \n",
    "                    help=\"from which epoch's checkpoint to continue training\")\n",
    "parser.add_argument('--hs', type=int, default=501, metavar='N',\n",
    "                    help='hidden size of GRUs')\n",
    "parser.add_argument('--nz', type=int, default=30, metavar='N',\n",
    "                    help='number of dimensions of latent vectors z')\n",
    "parser.add_argument('--bidirectional', action='store_true', default=True,\n",
    "                    help='whether to use bidirectional encoding')\n",
    "parser.add_argument('--predictor', action='store_true', default=False,\n",
    "                    help='whether to train a performance predictor from latent\\\n",
    "                    encodings and a VAE at the same time')\n",
    "# optimization settings\n",
    "parser.add_argument('--lr', type=float, default=1e-4, metavar='LR',\n",
    "                    help='learning rate (default: 1e-4)')\n",
    "parser.add_argument('--epochs', type=int, default=100, metavar='N',\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--batch-size', type=int, default=32, metavar='N',\n",
    "                    help='batch size during training')\n",
    "parser.add_argument('--infer-batch-size', type=int, default=32, metavar='N',\n",
    "                    help='batch size during inference')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--all-gpus', action='store_true', default=True,\n",
    "                    help='use all available GPUs')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "print(args)\n",
    "\n",
    "\n",
    "args.file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "args.res_dir = os.path.join(args.file_dir, 'results/{}{}'.format(args.data_name, \n",
    "                                                                 args.save_appendix))\n",
    "\n",
    "train_data, validation_data,test_data, graph_args = load_bench102_graphs(args.data_name, n_types=args.nvt,fmt='igraph')\n",
    "\n",
    "model_dvae = eval(args.model)(\n",
    "        graph_args.max_n, \n",
    "        graph_args.num_vertex_type, \n",
    "        graph_args.START_TYPE, \n",
    "        graph_args.END_TYPE, \n",
    "        hs=args.hs, \n",
    "        nz=args.nz, \n",
    "        bidirectional=args.bidirectional\n",
    "        )\n",
    "\n",
    "optimizer = optim.Adam(model_dvae.parameters(), lr=args.lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "model_dvae.to(device)\n",
    "\n",
    "model_dvae.load_state_dict(torch.load('./data_dvae/bench102_model.pt'))  ##################DVAE,,     \n",
    "\n",
    "\n",
    "model_linear_nn=torch.nn.Sequential(\n",
    "    torch.nn.Linear(31,100),\n",
    "    torch.nn.ReLU(),    \n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(100,100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100,args.nz),\n",
    "     )\n",
    "\n",
    "####A simple linear model that project vector data to latent representtaion in DVAE\n",
    "model_linear_nn.load_state_dict(torch.load('./data_dvae/model_linear_nn.pt')) \n",
    "\n",
    "\n",
    "\n",
    "pbar_test= tqdm(test_data)\n",
    "g_test=[]\n",
    "for i, (g,y) in enumerate(pbar_test):\n",
    "    g_test.append(g)\n",
    "mu, logvar= model_dvae.encode(g_test[2])\n",
    "z = model_dvae.reparameterize(mu, logvar)\n",
    "m_type=z.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.autograd.gradcheck import zero_gradients\n",
    "import scipy.stats\n",
    "\n",
    "def update_arch_archive(arch_archive,numb_store):\n",
    "    arch_archive=arch_archive[:-numb_store]   \n",
    "    return arch_archive\n",
    "\n",
    "def cal_novelty(sampled_arch,arch_archive):\n",
    "    \n",
    "    def comp_zeros(arch_archive):\n",
    "        \n",
    "        arch_archive_t=torch.Tensor(arch_archive)\n",
    "        app=torch.zeros(arch_archive_t.shape[0],25)\n",
    "        arch_archive_com=torch.cat((arch_archive_t,app),1)\n",
    "        \n",
    "        return arch_archive_com   \n",
    "    \n",
    "    def cal_arch_dis(list1,list2):#################small distance more similar\n",
    "        dis=6\n",
    "        n_nodes=6######genotypes.STEPS\n",
    "\n",
    "        for i in range(n_nodes):\n",
    "            if list1[i]==list1[i]:\n",
    "                dis=dis-1                   \n",
    "        dis=dis/6\n",
    "        return dis \n",
    "\n",
    "    def decoder_ori_list(list1):\n",
    "        z_test_pred = model_linear_nn(list1)    \n",
    "        uu=z_test_pred-m_type.detach()+m_type\n",
    "        uu=uu.to(device)\n",
    "        g_r=model_dvae.decode(uu)\n",
    "        ff=g_r[0].vs['type']\n",
    "        ind=[2,4,5,7,8,9]\n",
    "        decoder_l=[]\n",
    "        for u in range(6):\n",
    "            decoder_l.extend([ff[ind[u]]])\n",
    "        return decoder_l\n",
    "\n",
    "    \n",
    "    \n",
    "    def compute_jacobian(inputs, output):\n",
    "        \"\"\"\n",
    "        :param inputs: Batch X Size (e.g. Depth X Width X Height)\n",
    "        :param output: Batch X Classes\n",
    "        :return: jacobian: Batch X Classes X Size\n",
    "        \"\"\"\n",
    "        assert inputs.requires_grad\n",
    "\n",
    "        num_classes = output.size()[1]\n",
    "\n",
    "        jacobian = torch.zeros(num_classes, *inputs.size())\n",
    "        grad_output = torch.zeros(*output.size())\n",
    "        if inputs.is_cuda:\n",
    "            grad_output = grad_output.cuda()\n",
    "            jacobian = jacobian.cuda()\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            zero_gradients(inputs)\n",
    "            grad_output.zero_()\n",
    "            grad_output[:, i] = 1\n",
    "            output.backward(grad_output, retain_graph=True)\n",
    "            jacobian[i] = inputs.grad.data\n",
    "\n",
    "        return torch.transpose(jacobian, dim0=0, dim1=1)\n",
    "    \n",
    "    arch_archive_com=comp_zeros(arch_archive)##########\n",
    "    archive_f=Variable(arch_archive_com, requires_grad=True)\n",
    "    archive_z=model_linear_nn(archive_f)\n",
    "    \n",
    "    sampled_arch_com=comp_zeros([sampled_arch])##########\n",
    "    sampled_arch_f=Variable(sampled_arch_com[0], requires_grad=True)\n",
    "    sampled_arch_z=model_linear_nn(sampled_arch_f)\n",
    "        \n",
    "    \n",
    "    J = compute_jacobian(archive_f, archive_z)\n",
    "    J = J.cpu().numpy()\n",
    "\n",
    "    z_size=args.nz#######we set the input dimension as 31, and latent dimensin 30 for easy computation\n",
    "    train_w=np.array(archive_z.data)\n",
    "    gennorm_param = np.zeros([3, z_size])######get the latent representation distribution (normal)\n",
    "    \n",
    "    for i in range(z_size):\n",
    "        betta, loc, scale = scipy.stats.gennorm.fit(train_w[:99, i])\n",
    "        gennorm_param[0, i] = betta\n",
    "        gennorm_param[1, i] = loc\n",
    "        gennorm_param[2, i] = scale\n",
    "    p = scipy.stats.gennorm.pdf(sampled_arch_z.data, gennorm_param[0, :], gennorm_param[1, :], gennorm_param[2, :])\n",
    "    logPz = np.sum(np.log(p))/30########get the average \n",
    "    if not np.isfinite(logPz):\n",
    "        logPz = -1000\n",
    "    \n",
    "    \n",
    "    u, s, vh = np.linalg.svd(J[0, :, :], full_matrices=False)\n",
    "\n",
    "    logD = np.sum(np.log(np.abs(s[:6])))########ONLY consider the first 6 dimensions that are non-zero\n",
    "    \n",
    "\n",
    "    rlist = []\n",
    "    for i in range(len(arch_archive)):\n",
    "        decoder_l=decoder_ori_list(arch_archive_com[i])    \n",
    "        distance = cal_arch_dis(decoder_l,arch_archive_com[i])\n",
    "        rlist.append(distance)    \n",
    "    counts, bin_edges = np.histogram(rlist, bins=6, normed=True)    \n",
    "\n",
    "    darts_r=decoder_ori_list(arch_archive_com)\n",
    "    darts_o=arch_archive_com\n",
    "    distance = cal_arch_dis(darts_r,darts_o)    \n",
    "\n",
    "    def r_pdf(x, bins, count):\n",
    "        if x < bins[0]:\n",
    "            return max(count[0], 1e-308)\n",
    "        if x >= bins[-1]:\n",
    "            return max(count[-1], 1e-308)\n",
    "        id = np.digitize(x, bins) - 1\n",
    "        return max(count[id], 1e-308)\n",
    "\n",
    "    logPe = np.log(r_pdf(distance, bin_edges, counts))    \n",
    "    \n",
    "    Novelty = (logD + logPz + logPe)/3##########we need to minimize this\n",
    "    \n",
    "    return Novelty\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_compensate(pre_index,cur_index,pre_hardwts,cur_hardwts):\n",
    "    compen_index   = cur_index\n",
    "    for i in range(pre_index.shape[0]):\n",
    "        if pre_index[i][0].item()==cur_index[i][0].item():\n",
    "            a=np.random.randint(5)\n",
    "            while a==pre_index[i][0].item():\n",
    "                a=np.random.randint(5)\n",
    "            compen_index[i][0]=a              \n",
    "    one_h   = torch.zeros(6,5).scatter_(-1, compen_index, 1.0).cuda()\n",
    "    compen_hardwts = one_h - cur_hardwts.detach() + cur_hardwts\n",
    "    \n",
    "    return compen_index,compen_hardwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def search_func(xloader, network, criterion, scheduler, w_optimizer, a_optimizer, epoch_str, print_freq, logger,arch_archive,ex_ep_ratio,multi_model_ratio):\n",
    "    data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "    base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    network.train()\n",
    "    end = time.time()\n",
    "\n",
    "    pre_index=0\n",
    "    \n",
    "    for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(xloader):\n",
    "      \n",
    "        scheduler.update(None, 1.0 * step / len(xloader))                   \n",
    "        base_targets = base_targets.cuda(non_blocking=True)\n",
    "        arch_targets = arch_targets.cuda(non_blocking=True)\n",
    "    # measure data loading time\n",
    "        data_time.update(time.time() - end)    \n",
    "    # update the weights\n",
    "        w_optimizer.zero_grad()\n",
    "\n",
    "######get the current arch loss                \n",
    "        _, logits,cur_index,cur_hardwts = network(base_inputs,0,0,0)\n",
    "        base_loss = criterion(logits, base_targets) \n",
    "        cur_index,cur_hardwts= network.module.get_index_hardwts()\n",
    "        \n",
    "######get the previous arch loss          \n",
    "        if step==0:\n",
    "            pre_index=cur_index\n",
    "            pre_hardwts=cur_hardwts   \n",
    "            \n",
    "        _, logits_p,_,_ = network(base_inputs,1,pre_index,pre_hardwts)\n",
    "        pre_loss = criterion(logits_p, base_targets).item() \n",
    "        \n",
    "######get the compensary arch loss                      \n",
    "        com_index,com_hardwts=cal_compensate(pre_index,cur_index,pre_hardwts,cur_hardwts)        \n",
    "        _, logits_c,_,_ = network(base_inputs,1,com_index,com_hardwts)\n",
    "        compen_loss = criterion(logits_c, base_targets).item()        \n",
    "\n",
    "      \n",
    "        eta=1-sigmoid_function(ex_ep_ratio)\n",
    "        \n",
    "        lbd=0.5\n",
    "        \n",
    "        cur_loss =(1-lbd)*base_loss.item()+lbd/2*(pre_loss+compen_loss)\n",
    "        cur_loss=base_loss+cur_loss-base_loss.detach()\n",
    "        \n",
    "        _, _,cur_index,cur_hardwts = network(base_inputs,0,0,0)########\n",
    "        cur_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(network.parameters(), 5)\n",
    "        w_optimizer.step()\n",
    "    # record\n",
    "        base_prec1, base_prec5 = obtain_accuracy(logits.data, base_targets.data, topk=(1, 5))\n",
    "        base_losses.update(base_loss.item(),  base_inputs.size(0))\n",
    "        base_top1.update  (base_prec1.item(), base_inputs.size(0))\n",
    "        base_top5.update  (base_prec5.item(), base_inputs.size(0))\n",
    "\n",
    "        pre_index=cur_index\n",
    "        pre_hardwts=cur_hardwts\n",
    "        \n",
    "        \n",
    "        \n",
    "###########update arch parameters         \n",
    "        arch_sample=network.module.gene()     \n",
    "        num_store=50########################################store data   size of A     \n",
    "        if len(arch_archive)<num_store:\n",
    "            Novelty=0\n",
    "        else:\n",
    "            Novelty=cal_novelty(arch_sample,arch_archive)\n",
    "                          \n",
    "    # update the architecture-weight\n",
    "        a_optimizer.zero_grad()\n",
    "        _, logits,_,_ = network(arch_inputs,0,0,0)\n",
    "        a_loss = criterion(logits, arch_targets)\n",
    "        \n",
    "        arch_loss=(1-eta)*a_loss+eta*Novelty#####################balance the exploration and exploitation\n",
    "\n",
    "        arch_loss.backward()\n",
    "        a_optimizer.step()\n",
    "    # record\n",
    "        arch_prec1, arch_prec5 = obtain_accuracy(logits.data, arch_targets.data, topk=(1, 5))\n",
    "        arch_losses.update(arch_loss.item(),  arch_inputs.size(0))\n",
    "        arch_top1.update  (arch_prec1.item(), arch_inputs.size(0))\n",
    "        arch_top5.update  (arch_prec5.item(), arch_inputs.size(0))\n",
    "\n",
    "    # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % print_freq == 0 or step + 1 == len(xloader):\n",
    "            Sstr = '*SEARCH* ' + time_string() + ' [{:}][{:03d}/{:03d}]'.format(epoch_str, step, len(xloader))\n",
    "            Tstr = 'Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})'.format(batch_time=batch_time, data_time=data_time)\n",
    "            Wstr = 'Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]'.format(loss=base_losses, top1=base_top1, top5=base_top5)\n",
    "            Astr = 'Arch [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]'.format(loss=arch_losses, top1=arch_top1, top5=arch_top5)\n",
    "            logger.log(Sstr + ' ' + Tstr + ' ' + Wstr + ' ' + Astr)\n",
    "            \n",
    "            \n",
    "        arch_archive.append(arch_sample)\n",
    "        arch_archive=arch_archive[-num_store:]##################consider number of previous\n",
    "    return base_losses.avg, base_top1.avg, base_top5.avg, arch_losses.avg, arch_top1.avg, arch_top5.avg,arch_archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function with logger : Logger(dir=EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10, use-tf=False, writer=None)\n",
      "Arguments : -------------------------------\n",
      "all_gpus         : True\n",
      "arch_learning_rate : 0.0003\n",
      "arch_nas_dataset : /home/jiahzhao/Data/NAS-Projects-master/NAS-Bench-102-v1_0-e61699.pth\n",
      "arch_weight_decay : 0.001\n",
      "batch_size       : 32\n",
      "bidirectional    : True\n",
      "channel          : 16\n",
      "config_path      : /home/jiahzhao/Data/NAS-Projects-master/configs/nas-benchmark/algos/EENAS.config\n",
      "continue_from    : None\n",
      "cuda             : True\n",
      "data_name        : ./data_dvae/bench_102_num\n",
      "data_path        : /data/jiahzhao/ENNAS_benchmark102/data/cifar-10-batches-py\n",
      "data_type        : ENAS\n",
      "dataset          : cifar10\n",
      "epochs           : 100\n",
      "file_dir         : /data/jiahzhao/NAS-Projects-master/exps/algos\n",
      "hs               : 501\n",
      "infer_batch_size : 32\n",
      "keep_old         : False\n",
      "load_latest_model : False\n",
      "lr               : 0.0001\n",
      "max_nodes        : 4\n",
      "model            : DVAE\n",
      "no_cuda          : False\n",
      "no_test          : False\n",
      "num_cells        : 5\n",
      "nvt              : 5\n",
      "nz               : 30\n",
      "only_test        : False\n",
      "predictor        : False\n",
      "print_freq       : 200\n",
      "rand_seed        : 0\n",
      "reprocess        : False\n",
      "res_dir          : /data/jiahzhao/NAS-Projects-master/exps/algos/results/./data_dvae/bench_102_num\n",
      "sample_number    : 20\n",
      "save_appendix    : \n",
      "save_dir         : ./EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10\n",
      "save_interval    : 100\n",
      "search_space_name : nas-bench-102\n",
      "seed             : 1\n",
      "small_train      : False\n",
      "tau_max          : 10\n",
      "tau_min          : 0.1\n",
      "track_running_stats : 1\n",
      "workers          : 2\n",
      "Python  Version  : 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56)  [GCC 7.2.0]\n",
      "Pillow  Version  : 5.1.0\n",
      "PyTorch Version  : 1.0.1.post2\n",
      "cuDNN   Version  : 7402\n",
      "CUDA available   : True\n",
      "CUDA GPU numbers : 2\n",
      "CUDA_VISIBLE_DEVICES : None\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Load split file from /home/jiahzhao/Data/NAS-Projects-master/configs/nas-benchmark/cifar-split.txt\n",
      "/home/jiahzhao/Data/NAS-Projects-master/configs/nas-benchmark/algos/EENAS.config\n",
      "Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=250, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, class_num=10, xshape=(1, 3, 32, 32))\n",
      "||||||| cifar10    ||||||| Search-Loader-Num=391, batch size=64\n",
      "||||||| cifar10    ||||||| Config=Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=250, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, class_num=10, xshape=(1, 3, 32, 32))\n",
      "search-model :\n",
      "TinyNetworkEENAS(\n",
      "  TinyNetworkEENAS(C=16, Max-Nodes=4, N=5, L=17)\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (cells): ModuleList(\n",
      "    (0): SearchCell(\n",
      "      info :: 4 nodes, inC=16, outC=16\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): SearchCell(\n",
      "      info :: 4 nodes, inC=16, outC=16\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): SearchCell(\n",
      "      info :: 4 nodes, inC=16, outC=16\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): SearchCell(\n",
      "      info :: 4 nodes, inC=16, outC=16\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): SearchCell(\n",
      "      info :: 4 nodes, inC=16, outC=16\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=16, C_out=16, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): ResNetBasicblock(\n",
      "      ResNetBasicblock(inC=16, outC=32, stride=2)\n",
      "      (conv_a): ReLUConvBN(\n",
      "        (op): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (conv_b): ReLUConvBN(\n",
      "        (op): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): SearchCell(\n",
      "      info :: 4 nodes, inC=32, outC=32\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): SearchCell(\n",
      "      info :: 4 nodes, inC=32, outC=32\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): SearchCell(\n",
      "      info :: 4 nodes, inC=32, outC=32\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SearchCell(\n",
      "      info :: 4 nodes, inC=32, outC=32\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): SearchCell(\n",
      "      info :: 4 nodes, inC=32, outC=32\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=32, C_out=32, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): ResNetBasicblock(\n",
      "      ResNetBasicblock(inC=32, outC=64, stride=2)\n",
      "      (conv_a): ReLUConvBN(\n",
      "        (op): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (conv_b): ReLUConvBN(\n",
      "        (op): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (12): SearchCell(\n",
      "      info :: 4 nodes, inC=64, outC=64\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): SearchCell(\n",
      "      info :: 4 nodes, inC=64, outC=64\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): SearchCell(\n",
      "      info :: 4 nodes, inC=64, outC=64\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): SearchCell(\n",
      "      info :: 4 nodes, inC=64, outC=64\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): SearchCell(\n",
      "      info :: 4 nodes, inC=64, outC=64\n",
      "      (edges): ModuleDict(\n",
      "        (1<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (2<-1): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-0): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-1): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "        (3<-2): ModuleList(\n",
      "          (0): Zero(C_in=64, C_out=64, stride=1)\n",
      "          (1): Identity()\n",
      "          (2): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): ReLUConvBN(\n",
      "            (op): Sequential(\n",
      "              (0): ReLU()\n",
      "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): POOLING(\n",
      "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lastact): Sequential(\n",
      "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace)\n",
      "  )\n",
      "  (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "w-optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.025\n",
      "    lr: 0.025\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "a-optimizer : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.5, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0003\n",
      "    weight_decay: 0.001\n",
      ")\n",
      "w-scheduler : CosineAnnealingLR(warmup=0, max-epoch=250, current::epoch=0, iter=0.00, type=cosine, T-max=250, eta-min=0.001)\n",
      "criterion   : CrossEntropyLoss()\n",
      "search-space : ['none', 'skip_connect', 'nor_conv_1x1', 'nor_conv_3x3', 'avg_pool_3x3']\n",
      "try to create the NAS-Bench-102 api from /home/jiahzhao/Data/NAS-Projects-master/NAS-Bench-102-v1_0-e61699.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-27 12:38:21] create API = NASBench102API(15625/15625 architectures) done\n",
      "=> loading checkpoint of the last-info 'EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth' start\n",
      "=> loading checkpoint of the last-info '{'epoch': 237, 'args': Namespace(all_gpus=True, arch_learning_rate=0.0003, arch_nas_dataset='/home/jiahzhao/Data/NAS-Projects-master/NAS-Bench-102-v1_0-e61699.pth', arch_weight_decay=0.001, batch_size=32, bidirectional=True, channel=16, config_path='/home/jiahzhao/Data/NAS-Projects-master/configs/nas-benchmark/algos/EENAS.config', continue_from=None, cuda=True, data_name='./data_dvae/bench_102_num', data_path='/data/jiahzhao/ENNAS_benchmark102/data/cifar-10-batches-py', data_type='ENAS', dataset='cifar10', epochs=100, file_dir='/data/jiahzhao/NAS-Projects-master/exps/algos', hs=501, infer_batch_size=32, keep_old=False, load_latest_model=False, lr=0.0001, max_nodes=4, model='DVAE', no_cuda=False, no_test=False, num_cells=5, nvt=5, nz=30, only_test=False, predictor=False, print_freq=200, rand_seed=0, reprocess=False, res_dir='/data/jiahzhao/NAS-Projects-master/exps/algos/results/./data_dvae/bench_102_num', sample_number=20, save_appendix='', save_dir='./EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10', save_interval=100, search_space_name='nas-bench-102', seed=1, small_train=False, tau_max=10, tau_min=0.1, track_running_stats=1, workers=2), 'last_checkpoint': PosixPath('EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth')}' start with 237-th epoch.\n",
      "\n",
      "[Search the 237-250-th epoch] Time Left: [00:00:00], tau=0.5771084337349386, LR=0.0011597686695055836\n",
      "*SEARCH* [2020-01-27 12:38:24] [237-250][000/391] Time 1.62 (1.62) Data 0.37 (0.37) Base [Loss 0.345 (0.345)  Prec@1 85.94 (85.94) Prec@5 100.00 (100.00)] Arch [Loss 0.690 (0.690)  Prec@1 79.69 (79.69) Prec@5 98.44 (98.44)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jiahzhao/anaconda3/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py:6290: RuntimeWarning: overflow encountered in power\n",
      "  return np.log(0.5*beta) - sc.gammaln(1.0/beta) - abs(x)**beta\n",
      "/data/jiahzhao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:90: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2020-01-27 12:44:49] [237-250][200/391] Time 2.10 (1.93) Data 0.00 (0.00) Base [Loss 0.475 (0.504)  Prec@1 87.50 (82.48) Prec@5 100.00 (99.02)] Arch [Loss 0.592 (0.614)  Prec@1 84.38 (78.53) Prec@5 98.44 (98.62)]\n",
      "*SEARCH* [2020-01-27 12:51:52] [237-250][390/391] Time 2.11 (2.07) Data 0.00 (0.00) Base [Loss 0.444 (0.490)  Prec@1 85.00 (82.95) Prec@5 100.00 (99.11)] Arch [Loss 1.029 (0.617)  Prec@1 67.50 (78.53) Prec@5 97.50 (98.67)]\n",
      "[237-250] searching : loss=0.49, accuracy@1=82.95%, accuracy@5=99.11%, time-cost=810.3 s\n",
      "[237-250] evaluate  : loss=0.62, accuracy@1=78.53%, accuracy@5=98.67%\n",
      "<<<--->>> The 237-250-th epoch : Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0148, 0.0148, 0.0136, 0.0155, 0.0148, 0.0151, 0.0151, 0.0144, 0.0189,\n",
      "         0.0151, 0.0151, 0.0151, 0.0151, 0.0182, 0.0135, 0.0472, 0.0488, 0.0725,\n",
      "         0.1782, 0.0478, 0.0319, 0.0478, 0.0475, 0.0157, 0.0371, 0.0477, 0.0478,\n",
      "         0.0384, 0.0147, 0.0478]])\n",
      "|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=10436\n",
      "cifar10-valid  FLOP=157.21 M, Params=1.101 MB, latency=21.70 ms.\n",
      "cifar10-valid  train : [loss = 0.002, top1 = 99.98%], valid : [loss = 0.504, top1 = 90.24%]\n",
      "cifar10        FLOP=157.21 M, Params=1.101 MB, latency=22.30 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.302, top1 = 93.79%]\n",
      "cifar100       FLOP=157.21 M, Params=1.107 MB, latency=21.40 ms.\n",
      "cifar100       train : [loss = 0.037, top1 = 99.63%], valid : [loss = 1.303, top1 = 71.36%], test : [loss = 1.246, top1 = 72.04%]\n",
      "ImageNet16-120 FLOP= 39.31 M, Params=1.109 MB, latency=19.45 ms.\n",
      "ImageNet16-120 train : [loss = 1.635, top1 = 55.91%], valid : [loss = 2.164, top1 = 44.40%], test : [loss = 2.177, top1 = 45.17%]\n",
      "\n",
      "[Search the 238-250-th epoch] Time Left: [02:42:07], tau=0.5373493975903596, LR=0.0011361790631450326\n",
      "*SEARCH* [2020-01-27 12:51:55] [238-250][000/391] Time 2.84 (2.84) Data 0.38 (0.38) Base [Loss 0.356 (0.356)  Prec@1 85.94 (85.94) Prec@5 100.00 (100.00)] Arch [Loss 0.378 (0.378)  Prec@1 87.50 (87.50) Prec@5 100.00 (100.00)]\n",
      "*SEARCH* [2020-01-27 12:59:23] [238-250][200/391] Time 2.08 (2.24) Data 0.00 (0.00) Base [Loss 0.350 (0.472)  Prec@1 84.38 (83.35) Prec@5 100.00 (99.33)] Arch [Loss 0.716 (0.613)  Prec@1 76.56 (79.38) Prec@5 98.44 (98.76)]\n",
      "*SEARCH* [2020-01-27 13:06:29] [238-250][390/391] Time 2.10 (2.24) Data 0.00 (0.00) Base [Loss 0.388 (0.478)  Prec@1 87.50 (83.30) Prec@5 100.00 (99.32)] Arch [Loss 0.322 (0.608)  Prec@1 87.50 (79.57) Prec@5 100.00 (98.70)]\n",
      "[238-250] searching : loss=0.48, accuracy@1=83.30%, accuracy@5=99.32%, time-cost=1687.1 s\n",
      "[238-250] evaluate  : loss=0.61, accuracy@1=79.57%, accuracy@5=98.70%\n",
      "<<<--->>> The 238-250-th epoch : Structure(4 nodes with |nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0146, 0.0146, 0.0134, 0.0152, 0.0146, 0.0149, 0.0149, 0.0143, 0.0188,\n",
      "         0.0149, 0.0149, 0.0149, 0.0149, 0.0178, 0.0132, 0.0473, 0.0495, 0.0732,\n",
      "         0.1789, 0.0479, 0.0321, 0.0479, 0.0476, 0.0154, 0.0373, 0.0479, 0.0479,\n",
      "         0.0387, 0.0146, 0.0479]])\n",
      "|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=81\n",
      "cifar10-valid  FLOP=153.27 M, Params=1.073 MB, latency=22.15 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.415, top1 = 91.35%]\n",
      "cifar10        FLOP=153.27 M, Params=1.073 MB, latency=21.24 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.254, top1 = 94.30%]\n",
      "cifar100       FLOP=153.28 M, Params=1.079 MB, latency=19.66 ms.\n",
      "cifar100       train : [loss = 0.021, top1 = 99.87%], valid : [loss = 1.272, top1 = 72.77%], test : [loss = 1.274, top1 = 72.30%]\n",
      "ImageNet16-120 FLOP= 38.33 M, Params=1.081 MB, latency=18.41 ms.\n",
      "ImageNet16-120 train : [loss = 1.124, top1 = 68.73%], valid : [loss = 2.251, top1 = 45.53%], test : [loss = 2.235, top1 = 46.44%]\n",
      "\n",
      "[Search the 239-250-th epoch] Time Left: [02:40:48], tau=0.49759036144578417, LR=0.0011144628916401858\n",
      "*SEARCH* [2020-01-27 13:06:32] [239-250][000/391] Time 2.70 (2.70) Data 0.39 (0.39) Base [Loss 0.438 (0.438)  Prec@1 84.38 (84.38) Prec@5 100.00 (100.00)] Arch [Loss 0.352 (0.352)  Prec@1 90.62 (90.62) Prec@5 100.00 (100.00)]\n",
      "*SEARCH* [2020-01-27 13:14:08] [239-250][200/391] Time 2.27 (2.28) Data 0.00 (0.00) Base [Loss 0.936 (0.500)  Prec@1 57.81 (82.49) Prec@5 98.44 (99.18)] Arch [Loss 1.080 (0.608)  Prec@1 59.38 (79.14) Prec@5 96.88 (98.69)]\n",
      "*SEARCH* [2020-01-27 13:21:22] [239-250][390/391] Time 2.23 (2.28) Data 0.00 (0.00) Base [Loss 0.457 (0.493)  Prec@1 90.00 (82.83) Prec@5 100.00 (99.12)] Arch [Loss 1.031 (0.620)  Prec@1 52.50 (78.70) Prec@5 97.50 (98.66)]\n",
      "[239-250] searching : loss=0.49, accuracy@1=82.83%, accuracy@5=99.12%, time-cost=2579.9 s\n",
      "[239-250] evaluate  : loss=0.62, accuracy@1=78.70%, accuracy@5=98.66%\n",
      "<<<--->>> The 239-250-th epoch : Structure(4 nodes with |nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0143, 0.0143, 0.0130, 0.0150, 0.0143, 0.0147, 0.0147, 0.0140, 0.0186,\n",
      "         0.0147, 0.0147, 0.0147, 0.0147, 0.0174, 0.0130, 0.0475, 0.0503, 0.0738,\n",
      "         0.1799, 0.0481, 0.0322, 0.0481, 0.0478, 0.0151, 0.0376, 0.0481, 0.0481,\n",
      "         0.0389, 0.0143, 0.0481]])\n",
      "|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=81\n",
      "cifar10-valid  FLOP=153.27 M, Params=1.073 MB, latency=22.15 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.415, top1 = 91.35%]\n",
      "cifar10        FLOP=153.27 M, Params=1.073 MB, latency=21.24 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.254, top1 = 94.30%]\n",
      "cifar100       FLOP=153.28 M, Params=1.079 MB, latency=19.66 ms.\n",
      "cifar100       train : [loss = 0.021, top1 = 99.87%], valid : [loss = 1.272, top1 = 72.77%], test : [loss = 1.274, top1 = 72.30%]\n",
      "ImageNet16-120 FLOP= 38.33 M, Params=1.081 MB, latency=18.41 ms.\n",
      "ImageNet16-120 train : [loss = 1.124, top1 = 68.73%], valid : [loss = 2.251, top1 = 45.53%], test : [loss = 2.235, top1 = 46.44%]\n",
      "\n",
      "[Search the 240-250-th epoch] Time Left: [02:28:49], tau=0.4578313253012052, LR=0.0010946235842262668\n",
      "*SEARCH* [2020-01-27 13:21:26] [240-250][000/391] Time 2.88 (2.88) Data 0.38 (0.38) Base [Loss 0.351 (0.351)  Prec@1 87.50 (87.50) Prec@5 100.00 (100.00)] Arch [Loss 0.649 (0.649)  Prec@1 75.00 (75.00) Prec@5 98.44 (98.44)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2020-01-27 13:28:52] [240-250][200/391] Time 2.32 (2.23) Data 0.00 (0.00) Base [Loss 0.373 (0.479)  Prec@1 89.06 (83.61) Prec@5 98.44 (99.19)] Arch [Loss 0.630 (0.614)  Prec@1 78.12 (78.73) Prec@5 100.00 (98.80)]\n",
      "*SEARCH* [2020-01-27 13:36:00] [240-250][390/391] Time 2.15 (2.24) Data 0.00 (0.00) Base [Loss 0.920 (0.476)  Prec@1 65.00 (83.67) Prec@5 97.50 (99.18)] Arch [Loss 0.687 (0.612)  Prec@1 80.00 (78.90) Prec@5 100.00 (98.74)]\n",
      "[240-250] searching : loss=0.48, accuracy@1=83.67%, accuracy@5=99.18%, time-cost=3456.9 s\n",
      "[240-250] evaluate  : loss=0.61, accuracy@1=78.90%, accuracy@5=98.74%\n",
      "<<<--->>> The 240-250-th epoch : Structure(4 nodes with |nor_conv_1x1~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0143, 0.0143, 0.0129, 0.0149, 0.0143, 0.0147, 0.0147, 0.0139, 0.0186,\n",
      "         0.0147, 0.0147, 0.0147, 0.0147, 0.0172, 0.0129, 0.0474, 0.0518, 0.0741,\n",
      "         0.1797, 0.0480, 0.0319, 0.0480, 0.0477, 0.0151, 0.0376, 0.0480, 0.0480,\n",
      "         0.0391, 0.0142, 0.0480]])\n",
      "|nor_conv_1x1~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=15425\n",
      "cifar10-valid  FLOP=117.88 M, Params=0.830 MB, latency=18.19 ms.\n",
      "cifar10-valid  train : [loss = 0.002, top1 = 99.98%], valid : [loss = 0.432, top1 = 90.77%]\n",
      "cifar10        FLOP=117.88 M, Params=0.830 MB, latency=16.94 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.277, top1 = 93.99%]\n",
      "cifar100       FLOP=117.89 M, Params=0.836 MB, latency=18.65 ms.\n",
      "cifar100       train : [loss = 0.031, top1 = 99.73%], valid : [loss = 1.279, top1 = 72.12%], test : [loss = 1.271, top1 = 71.80%]\n",
      "ImageNet16-120 FLOP= 29.48 M, Params=0.838 MB, latency=23.16 ms.\n",
      "ImageNet16-120 train : [loss = 1.262, top1 = 65.22%], valid : [loss = 2.219, top1 = 44.63%], test : [loss = 2.261, top1 = 44.33%]\n",
      "\n",
      "[Search the 241-250-th epoch] Time Left: [02:11:35], tau=0.4180722891566262, LR=0.0010766642737598993\n",
      "*SEARCH* [2020-01-27 13:36:03] [241-250][000/391] Time 2.59 (2.59) Data 0.39 (0.39) Base [Loss 0.199 (0.199)  Prec@1 95.31 (95.31) Prec@5 100.00 (100.00)] Arch [Loss 0.568 (0.568)  Prec@1 79.69 (79.69) Prec@5 96.88 (96.88)]\n",
      "*SEARCH* [2020-01-27 13:43:41] [241-250][200/391] Time 2.20 (2.29) Data 0.00 (0.00) Base [Loss 0.521 (0.456)  Prec@1 82.81 (84.17) Prec@5 100.00 (99.22)] Arch [Loss 1.568 (0.614)  Prec@1 42.19 (78.85) Prec@5 90.62 (98.45)]\n",
      "*SEARCH* [2020-01-27 13:50:51] [241-250][390/391] Time 2.05 (2.28) Data 0.00 (0.00) Base [Loss 0.655 (0.456)  Prec@1 82.50 (84.21) Prec@5 97.50 (99.25)] Arch [Loss 1.085 (0.615)  Prec@1 60.00 (78.96) Prec@5 100.00 (98.48)]\n",
      "[241-250] searching : loss=0.46, accuracy@1=84.21%, accuracy@5=99.25%, time-cost=4348.4 s\n",
      "[241-250] evaluate  : loss=0.61, accuracy@1=78.96%, accuracy@5=98.48%\n",
      "<<<--->>> The 241-250-th epoch : Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0141, 0.0141, 0.0127, 0.0147, 0.0141, 0.0145, 0.0145, 0.0137, 0.0184,\n",
      "         0.0145, 0.0145, 0.0145, 0.0145, 0.0170, 0.0127, 0.0475, 0.0533, 0.0745,\n",
      "         0.1803, 0.0481, 0.0320, 0.0481, 0.0478, 0.0148, 0.0378, 0.0481, 0.0481,\n",
      "         0.0391, 0.0141, 0.0481]])\n",
      "|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=2581\n",
      "cifar10-valid  FLOP=153.27 M, Params=1.073 MB, latency=21.15 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.421, top1 = 91.53%]\n",
      "cifar10        FLOP=153.27 M, Params=1.073 MB, latency=20.90 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.282, top1 = 94.22%]\n",
      "cifar100       FLOP=153.28 M, Params=1.079 MB, latency=19.65 ms.\n",
      "cifar100       train : [loss = 0.015, top1 = 99.90%], valid : [loss = 1.260, top1 = 73.13%], test : [loss = 1.232, top1 = 73.17%]\n",
      "ImageNet16-120 FLOP= 38.33 M, Params=1.081 MB, latency=22.08 ms.\n",
      "ImageNet16-120 train : [loss = 1.044, top1 = 70.80%], valid : [loss = 2.252, top1 = 46.32%], test : [loss = 2.247, top1 = 46.48%]\n",
      "\n",
      "[Search the 242-250-th epoch] Time Left: [01:58:54], tau=0.3783132530120472, LR=0.001060587796224398\n",
      "*SEARCH* [2020-01-27 13:50:55] [242-250][000/391] Time 2.81 (2.81) Data 0.38 (0.38) Base [Loss 0.487 (0.487)  Prec@1 84.38 (84.38) Prec@5 100.00 (100.00)] Arch [Loss 0.837 (0.837)  Prec@1 68.75 (68.75) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2020-01-27 13:58:32] [242-250][200/391] Time 2.32 (2.29) Data 0.00 (0.00) Base [Loss 0.230 (0.447)  Prec@1 92.19 (84.34) Prec@5 100.00 (99.32)] Arch [Loss 0.673 (0.617)  Prec@1 81.25 (79.21) Prec@5 98.44 (98.58)]\n",
      "*SEARCH* [2020-01-27 14:05:58] [242-250][390/391] Time 2.42 (2.32) Data 0.00 (0.00) Base [Loss 0.175 (0.446)  Prec@1 95.00 (84.30) Prec@5 100.00 (99.29)] Arch [Loss 0.604 (0.617)  Prec@1 82.50 (79.04) Prec@5 100.00 (98.61)]\n",
      "[242-250] searching : loss=0.45, accuracy@1=84.30%, accuracy@5=99.29%, time-cost=5255.1 s\n",
      "[242-250] evaluate  : loss=0.62, accuracy@1=79.04%, accuracy@5=98.61%\n",
      "<<<--->>> The 242-250-th epoch : Structure(4 nodes with |nor_conv_1x1~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|none~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0142, 0.0142, 0.0128, 0.0147, 0.0142, 0.0144, 0.0144, 0.0136, 0.0183,\n",
      "         0.0144, 0.0144, 0.0144, 0.0144, 0.0169, 0.0127, 0.0473, 0.0553, 0.0753,\n",
      "         0.1798, 0.0479, 0.0321, 0.0479, 0.0476, 0.0147, 0.0374, 0.0479, 0.0479,\n",
      "         0.0390, 0.0140, 0.0479]])\n",
      "|nor_conv_1x1~0|+|nor_conv_3x3~0|avg_pool_3x3~1|+|skip_connect~0|none~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=14228\n",
      "cifar10-valid  FLOP= 82.49 M, Params=0.587 MB, latency=16.83 ms.\n",
      "cifar10-valid  train : [loss = 0.002, top1 = 99.99%], valid : [loss = 0.447, top1 = 90.64%]\n",
      "cifar10        FLOP= 82.49 M, Params=0.587 MB, latency=16.09 ms.\n",
      "cifar10        train : [loss = 0.003, top1 = 99.96%], test  : [loss = 0.294, top1 = 93.73%]\n",
      "cifar100       FLOP= 82.50 M, Params=0.593 MB, latency=16.20 ms.\n",
      "cifar100       train : [loss = 0.066, top1 = 99.01%], valid : [loss = 1.360, top1 = 70.01%], test : [loss = 1.341, top1 = 70.37%]\n",
      "ImageNet16-120 FLOP= 20.63 M, Params=0.595 MB, latency=14.53 ms.\n",
      "ImageNet16-120 train : [loss = 1.531, top1 = 58.65%], valid : [loss = 2.260, top1 = 43.60%], test : [loss = 2.271, top1 = 43.47%]\n",
      "\n",
      "[Search the 243-250-th epoch] Time Left: [01:45:48], tau=0.3385542168674682, LR=0.00104639669028193\n",
      "*SEARCH* [2020-01-27 14:06:02] [243-250][000/391] Time 2.72 (2.72) Data 0.41 (0.41) Base [Loss 0.262 (0.262)  Prec@1 89.06 (89.06) Prec@5 100.00 (100.00)] Arch [Loss 0.399 (0.399)  Prec@1 84.38 (84.38) Prec@5 100.00 (100.00)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2020-01-27 14:13:45] [243-250][200/391] Time 2.37 (2.32) Data 0.00 (0.00) Base [Loss 0.223 (0.432)  Prec@1 93.75 (84.91) Prec@5 100.00 (99.16)] Arch [Loss 0.541 (0.604)  Prec@1 84.38 (79.37) Prec@5 98.44 (98.75)]\n",
      "*SEARCH* [2020-01-27 14:21:12] [243-250][390/391] Time 2.23 (2.33) Data 0.00 (0.00) Base [Loss 0.515 (0.453)  Prec@1 85.00 (84.32) Prec@5 97.50 (99.15)] Arch [Loss 0.513 (0.613)  Prec@1 80.00 (78.88) Prec@5 100.00 (98.66)]\n",
      "[243-250] searching : loss=0.45, accuracy@1=84.32%, accuracy@5=99.15%, time-cost=6168.3 s\n",
      "[243-250] evaluate  : loss=0.61, accuracy@1=78.88%, accuracy@5=98.66%\n",
      "<<<--->>> The 243-250-th epoch : Structure(4 nodes with |nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0139, 0.0139, 0.0125, 0.0145, 0.0139, 0.0142, 0.0142, 0.0134, 0.0181,\n",
      "         0.0142, 0.0142, 0.0142, 0.0142, 0.0166, 0.0125, 0.0474, 0.0564, 0.0760,\n",
      "         0.1804, 0.0480, 0.0323, 0.0480, 0.0478, 0.0144, 0.0375, 0.0480, 0.0480,\n",
      "         0.0392, 0.0138, 0.0480]])\n",
      "|nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=81\n",
      "cifar10-valid  FLOP=153.27 M, Params=1.073 MB, latency=22.15 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.415, top1 = 91.35%]\n",
      "cifar10        FLOP=153.27 M, Params=1.073 MB, latency=21.24 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.254, top1 = 94.30%]\n",
      "cifar100       FLOP=153.28 M, Params=1.079 MB, latency=19.66 ms.\n",
      "cifar100       train : [loss = 0.021, top1 = 99.87%], valid : [loss = 1.272, top1 = 72.77%], test : [loss = 1.274, top1 = 72.30%]\n",
      "ImageNet16-120 FLOP= 38.33 M, Params=1.081 MB, latency=18.41 ms.\n",
      "ImageNet16-120 train : [loss = 1.124, top1 = 68.73%], valid : [loss = 2.251, top1 = 45.53%], test : [loss = 2.235, top1 = 46.44%]\n",
      "\n",
      "[Search the 244-250-th epoch] Time Left: [01:31:20], tau=0.2987951807228928, LR=0.0010340931968726328\n",
      "*SEARCH* [2020-01-27 14:21:15] [244-250][000/391] Time 2.56 (2.56) Data 0.39 (0.39) Base [Loss 0.509 (0.509)  Prec@1 87.50 (87.50) Prec@5 96.88 (96.88)] Arch [Loss 0.826 (0.826)  Prec@1 70.31 (70.31) Prec@5 100.00 (100.00)]\n",
      "*SEARCH* [2020-01-27 14:29:07] [244-250][200/391] Time 2.28 (2.36) Data 0.00 (0.00) Base [Loss 0.684 (0.427)  Prec@1 81.25 (85.44) Prec@5 98.44 (99.29)] Arch [Loss 0.374 (0.602)  Prec@1 89.06 (79.24) Prec@5 100.00 (98.82)]\n",
      "*SEARCH* [2020-01-27 14:36:24] [244-250][390/391] Time 2.60 (2.33) Data 0.00 (0.00) Base [Loss 0.333 (0.437)  Prec@1 90.00 (84.82) Prec@5 100.00 (99.17)] Arch [Loss 1.023 (0.592)  Prec@1 60.00 (79.76) Prec@5 92.50 (98.76)]\n",
      "[244-250] searching : loss=0.44, accuracy@1=84.82%, accuracy@5=99.17%, time-cost=7079.9 s\n",
      "[244-250] evaluate  : loss=0.59, accuracy@1=79.76%, accuracy@5=98.76%\n",
      "<<<--->>> The 244-250-th epoch : Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0139, 0.0139, 0.0124, 0.0144, 0.0139, 0.0141, 0.0141, 0.0132, 0.0178,\n",
      "         0.0141, 0.0141, 0.0141, 0.0141, 0.0163, 0.0124, 0.0475, 0.0583, 0.0758,\n",
      "         0.1809, 0.0481, 0.0322, 0.0481, 0.0478, 0.0142, 0.0376, 0.0480, 0.0481,\n",
      "         0.0392, 0.0136, 0.0481]])\n",
      "|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=2581\n",
      "cifar10-valid  FLOP=153.27 M, Params=1.073 MB, latency=21.15 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.421, top1 = 91.53%]\n",
      "cifar10        FLOP=153.27 M, Params=1.073 MB, latency=20.90 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.282, top1 = 94.22%]\n",
      "cifar100       FLOP=153.28 M, Params=1.079 MB, latency=19.65 ms.\n",
      "cifar100       train : [loss = 0.015, top1 = 99.90%], valid : [loss = 1.260, top1 = 73.13%], test : [loss = 1.232, top1 = 73.17%]\n",
      "ImageNet16-120 FLOP= 38.33 M, Params=1.081 MB, latency=22.08 ms.\n",
      "ImageNet16-120 train : [loss = 1.044, top1 = 70.80%], valid : [loss = 2.252, top1 = 46.32%], test : [loss = 2.247, top1 = 46.48%]\n",
      "\n",
      "[Search the 245-250-th epoch] Time Left: [01:15:59], tau=0.2590361445783138, LR=0.0010236792588607412\n",
      "*SEARCH* [2020-01-27 14:36:27] [245-250][000/391] Time 2.70 (2.70) Data 0.39 (0.39) Base [Loss 0.202 (0.202)  Prec@1 92.19 (92.19) Prec@5 100.00 (100.00)] Arch [Loss 0.451 (0.451)  Prec@1 84.38 (84.38) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2020-01-27 14:44:08] [245-250][200/391] Time 2.23 (2.31) Data 0.00 (0.00) Base [Loss 0.221 (0.457)  Prec@1 89.06 (84.32) Prec@5 100.00 (99.18)] Arch [Loss 0.622 (0.609)  Prec@1 81.25 (79.24) Prec@5 98.44 (98.55)]\n",
      "*SEARCH* [2020-01-27 14:51:24] [245-250][390/391] Time 2.26 (2.30) Data 0.00 (0.00) Base [Loss 0.184 (0.449)  Prec@1 92.50 (84.42) Prec@5 100.00 (99.21)] Arch [Loss 0.901 (0.627)  Prec@1 62.50 (78.51) Prec@5 97.50 (98.50)]\n",
      "[245-250] searching : loss=0.45, accuracy@1=84.42%, accuracy@5=99.21%, time-cost=7980.2 s\n",
      "[245-250] evaluate  : loss=0.63, accuracy@1=78.51%, accuracy@5=98.50%\n",
      "<<<--->>> The 245-250-th epoch : Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0138, 0.0138, 0.0123, 0.0142, 0.0138, 0.0140, 0.0140, 0.0130, 0.0176,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0162, 0.0124, 0.0475, 0.0589, 0.0766,\n",
      "         0.1814, 0.0481, 0.0320, 0.0481, 0.0479, 0.0141, 0.0376, 0.0481, 0.0481,\n",
      "         0.0393, 0.0134, 0.0481]])\n",
      "|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=2581\n",
      "cifar10-valid  FLOP=153.27 M, Params=1.073 MB, latency=21.15 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.421, top1 = 91.53%]\n",
      "cifar10        FLOP=153.27 M, Params=1.073 MB, latency=20.90 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.282, top1 = 94.22%]\n",
      "cifar100       FLOP=153.28 M, Params=1.079 MB, latency=19.65 ms.\n",
      "cifar100       train : [loss = 0.015, top1 = 99.90%], valid : [loss = 1.260, top1 = 73.13%], test : [loss = 1.232, top1 = 73.17%]\n",
      "ImageNet16-120 FLOP= 38.33 M, Params=1.081 MB, latency=22.08 ms.\n",
      "ImageNet16-120 train : [loss = 1.044, top1 = 70.80%], valid : [loss = 2.252, top1 = 46.32%], test : [loss = 2.247, top1 = 46.48%]\n",
      "\n",
      "[Search the 246-250-th epoch] Time Left: [01:00:02], tau=0.21927710843373482, LR=0.0010151565207277904\n",
      "*SEARCH* [2020-01-27 14:51:28] [246-250][000/391] Time 2.87 (2.87) Data 0.41 (0.41) Base [Loss 0.253 (0.253)  Prec@1 92.19 (92.19) Prec@5 100.00 (100.00)] Arch [Loss 0.852 (0.852)  Prec@1 68.75 (68.75) Prec@5 98.44 (98.44)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2020-01-27 14:59:09] [246-250][200/391] Time 2.33 (2.31) Data 0.00 (0.00) Base [Loss 0.365 (0.480)  Prec@1 89.06 (83.40) Prec@5 100.00 (99.07)] Arch [Loss 0.845 (0.651)  Prec@1 70.31 (78.08) Prec@5 98.44 (98.38)]\n",
      "*SEARCH* [2020-01-27 15:06:22] [246-250][390/391] Time 2.60 (2.29) Data 0.00 (0.00) Base [Loss 0.819 (0.495)  Prec@1 67.50 (82.87) Prec@5 97.50 (98.99)] Arch [Loss 0.513 (0.652)  Prec@1 85.00 (78.01) Prec@5 100.00 (98.27)]\n",
      "[246-250] searching : loss=0.49, accuracy@1=82.87%, accuracy@5=98.99%, time-cost=8877.2 s\n",
      "[246-250] evaluate  : loss=0.65, accuracy@1=78.01%, accuracy@5=98.27%\n",
      "<<<--->>> The 246-250-th epoch : Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0134, 0.0134, 0.0121, 0.0139, 0.0134, 0.0138, 0.0138, 0.0127, 0.0172,\n",
      "         0.0138, 0.0138, 0.0138, 0.0138, 0.0159, 0.0122, 0.0477, 0.0600, 0.0776,\n",
      "         0.1823, 0.0483, 0.0322, 0.0483, 0.0481, 0.0137, 0.0377, 0.0483, 0.0483,\n",
      "         0.0392, 0.0131, 0.0483]])\n",
      "|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=2581\n",
      "cifar10-valid  FLOP=153.27 M, Params=1.073 MB, latency=21.15 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.421, top1 = 91.53%]\n",
      "cifar10        FLOP=153.27 M, Params=1.073 MB, latency=20.90 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.282, top1 = 94.22%]\n",
      "cifar100       FLOP=153.28 M, Params=1.079 MB, latency=19.65 ms.\n",
      "cifar100       train : [loss = 0.015, top1 = 99.90%], valid : [loss = 1.260, top1 = 73.13%], test : [loss = 1.232, top1 = 73.17%]\n",
      "ImageNet16-120 FLOP= 38.33 M, Params=1.081 MB, latency=22.08 ms.\n",
      "ImageNet16-120 train : [loss = 1.044, top1 = 70.80%], valid : [loss = 2.252, top1 = 46.32%], test : [loss = 2.247, top1 = 46.48%]\n",
      "\n",
      "[Search the 247-250-th epoch] Time Left: [00:44:52], tau=0.17951807228915584, LR=0.0010085263283129296\n",
      "*SEARCH* [2020-01-27 15:06:25] [247-250][000/391] Time 2.88 (2.88) Data 0.42 (0.42) Base [Loss 0.210 (0.210)  Prec@1 90.62 (90.62) Prec@5 100.00 (100.00)] Arch [Loss 0.619 (0.619)  Prec@1 78.12 (78.12) Prec@5 96.88 (96.88)]\n",
      "*SEARCH* [2020-01-27 15:13:59] [247-250][200/391] Time 2.18 (2.28) Data 0.00 (0.00) Base [Loss 0.420 (0.493)  Prec@1 85.94 (82.86) Prec@5 100.00 (98.94)] Arch [Loss 0.685 (0.637)  Prec@1 76.56 (78.33) Prec@5 98.44 (98.47)]\n",
      "*SEARCH* [2020-01-27 15:21:03] [247-250][390/391] Time 2.29 (2.25) Data 0.00 (0.00) Base [Loss 1.053 (0.484)  Prec@1 65.00 (83.10) Prec@5 97.50 (99.06)] Arch [Loss 0.660 (0.639)  Prec@1 80.00 (78.38) Prec@5 97.50 (98.41)]\n",
      "[247-250] searching : loss=0.48, accuracy@1=83.10%, accuracy@5=99.06%, time-cost=9758.1 s\n",
      "[247-250] evaluate  : loss=0.64, accuracy@1=78.38%, accuracy@5=98.41%\n",
      "<<<--->>> The 247-250-th epoch : Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0133, 0.0133, 0.0119, 0.0137, 0.0133, 0.0136, 0.0136, 0.0125, 0.0169,\n",
      "         0.0136, 0.0136, 0.0136, 0.0136, 0.0157, 0.0121, 0.0479, 0.0612, 0.0773,\n",
      "         0.1831, 0.0484, 0.0324, 0.0484, 0.0482, 0.0135, 0.0378, 0.0484, 0.0484,\n",
      "         0.0393, 0.0129, 0.0484]])\n",
      "|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|nor_conv_1x1~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=10436\n",
      "cifar10-valid  FLOP=157.21 M, Params=1.101 MB, latency=21.70 ms.\n",
      "cifar10-valid  train : [loss = 0.002, top1 = 99.98%], valid : [loss = 0.504, top1 = 90.24%]\n",
      "cifar10        FLOP=157.21 M, Params=1.101 MB, latency=22.30 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.302, top1 = 93.79%]\n",
      "cifar100       FLOP=157.21 M, Params=1.107 MB, latency=21.40 ms.\n",
      "cifar100       train : [loss = 0.037, top1 = 99.63%], valid : [loss = 1.303, top1 = 71.36%], test : [loss = 1.246, top1 = 72.04%]\n",
      "ImageNet16-120 FLOP= 39.31 M, Params=1.109 MB, latency=19.45 ms.\n",
      "ImageNet16-120 train : [loss = 1.635, top1 = 55.91%], valid : [loss = 2.164, top1 = 44.40%], test : [loss = 2.177, top1 = 45.17%]\n",
      "\n",
      "[Search the 248-250-th epoch] Time Left: [00:29:22], tau=0.13975903614457685, LR=0.0010037897286004007\n",
      "*SEARCH* [2020-01-27 15:21:06] [248-250][000/391] Time 2.70 (2.70) Data 0.42 (0.42) Base [Loss 0.072 (0.072)  Prec@1 98.44 (98.44) Prec@5 100.00 (100.00)] Arch [Loss 0.203 (0.203)  Prec@1 92.19 (92.19) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2020-01-27 15:28:35] [248-250][200/391] Time 2.22 (2.25) Data 0.00 (0.00) Base [Loss 0.348 (0.519)  Prec@1 84.38 (81.96) Prec@5 100.00 (98.70)] Arch [Loss 0.689 (0.618)  Prec@1 70.31 (79.06) Prec@5 100.00 (98.62)]\n",
      "*SEARCH* [2020-01-27 15:35:07] [248-250][390/391] Time 1.66 (2.16) Data 0.00 (0.00) Base [Loss 0.569 (0.501)  Prec@1 75.00 (82.58) Prec@5 97.50 (98.77)] Arch [Loss 0.350 (0.627)  Prec@1 82.50 (78.73) Prec@5 100.00 (98.54)]\n",
      "[248-250] searching : loss=0.50, accuracy@1=82.58%, accuracy@5=98.77%, time-cost=10602.3 s\n",
      "[248-250] evaluate  : loss=0.63, accuracy@1=78.73%, accuracy@5=98.54%\n",
      "<<<--->>> The 248-250-th epoch : Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0133, 0.0133, 0.0120, 0.0137, 0.0133, 0.0137, 0.0137, 0.0124, 0.0169,\n",
      "         0.0137, 0.0137, 0.0137, 0.0137, 0.0159, 0.0123, 0.0476, 0.0617, 0.0784,\n",
      "         0.1825, 0.0482, 0.0326, 0.0482, 0.0480, 0.0135, 0.0378, 0.0482, 0.0482,\n",
      "         0.0389, 0.0130, 0.0482]])\n",
      "|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=2581\n",
      "cifar10-valid  FLOP=153.27 M, Params=1.073 MB, latency=21.15 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.421, top1 = 91.53%]\n",
      "cifar10        FLOP=153.27 M, Params=1.073 MB, latency=20.90 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.282, top1 = 94.22%]\n",
      "cifar100       FLOP=153.28 M, Params=1.079 MB, latency=19.65 ms.\n",
      "cifar100       train : [loss = 0.015, top1 = 99.90%], valid : [loss = 1.260, top1 = 73.13%], test : [loss = 1.232, top1 = 73.17%]\n",
      "ImageNet16-120 FLOP= 38.33 M, Params=1.081 MB, latency=22.08 ms.\n",
      "ImageNet16-120 train : [loss = 1.044, top1 = 70.80%], valid : [loss = 2.252, top1 = 46.32%], test : [loss = 2.247, top1 = 46.48%]\n",
      "\n",
      "[Search the 249-250-th epoch] Time Left: [00:14:04], tau=0.09999999999999964, LR=0.0010009474695542066\n",
      "*SEARCH* [2020-01-27 15:35:10] [249-250][000/391] Time 2.37 (2.37) Data 0.42 (0.42) Base [Loss 0.264 (0.264)  Prec@1 92.19 (92.19) Prec@5 100.00 (100.00)] Arch [Loss 0.630 (0.630)  Prec@1 78.12 (78.12) Prec@5 100.00 (100.00)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2020-01-27 15:41:15] [249-250][200/391] Time 1.87 (1.83) Data 0.00 (0.00) Base [Loss 0.195 (0.427)  Prec@1 93.75 (85.12) Prec@5 100.00 (99.28)] Arch [Loss 0.300 (0.609)  Prec@1 87.50 (79.52) Prec@5 100.00 (98.71)]\n",
      "*SEARCH* [2020-01-27 15:47:06] [249-250][390/391] Time 1.81 (1.84) Data 0.00 (0.00) Base [Loss 0.389 (0.435)  Prec@1 92.50 (84.98) Prec@5 100.00 (99.17)] Arch [Loss 0.351 (0.591)  Prec@1 90.00 (80.26) Prec@5 97.50 (98.71)]\n",
      "[249-250] searching : loss=0.43, accuracy@1=84.98%, accuracy@5=99.17%, time-cost=11321.2 s\n",
      "[249-250] evaluate  : loss=0.59, accuracy@1=80.26%, accuracy@5=98.71%\n",
      "<<<--->>> The 249-250-th epoch : Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|)\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/checkpoint/seed-0-basic.pth\n",
      "Find EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into EENAS_ratio_10_0.5_seed0/output/search-cell-nas-bench-102-cifar10/seed-0-last-info.pth\n",
      "arch-parameters :\n",
      "tensor([[0.0133, 0.0133, 0.0121, 0.0136, 0.0133, 0.0136, 0.0136, 0.0124, 0.0167,\n",
      "         0.0136, 0.0136, 0.0136, 0.0136, 0.0158, 0.0122, 0.0476, 0.0621, 0.0794,\n",
      "         0.1826, 0.0481, 0.0325, 0.0481, 0.0479, 0.0134, 0.0378, 0.0481, 0.0481,\n",
      "         0.0390, 0.0127, 0.0481]])\n",
      "|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=2581\n",
      "cifar10-valid  FLOP=153.27 M, Params=1.073 MB, latency=21.15 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.421, top1 = 91.53%]\n",
      "cifar10        FLOP=153.27 M, Params=1.073 MB, latency=20.90 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.282, top1 = 94.22%]\n",
      "cifar100       FLOP=153.28 M, Params=1.079 MB, latency=19.65 ms.\n",
      "cifar100       train : [loss = 0.015, top1 = 99.90%], valid : [loss = 1.260, top1 = 73.13%], test : [loss = 1.232, top1 = 73.17%]\n",
      "ImageNet16-120 FLOP= 38.33 M, Params=1.081 MB, latency=22.08 ms.\n",
      "ImageNet16-120 train : [loss = 1.044, top1 = 70.80%], valid : [loss = 2.252, top1 = 46.32%], test : [loss = 2.247, top1 = 46.48%]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "EENAS : run 250 epochs, cost 11321.2 s, last-geno is Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|).\n",
      "|nor_conv_3x3~0|+|nor_conv_1x1~0|nor_conv_3x3~1|+|skip_connect~0|nor_conv_3x3~1|nor_conv_3x3~2|\n",
      "datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=2581\n",
      "cifar10-valid  FLOP=153.27 M, Params=1.073 MB, latency=21.15 ms.\n",
      "cifar10-valid  train : [loss = 0.001, top1 = 99.99%], valid : [loss = 0.421, top1 = 91.53%]\n",
      "cifar10        FLOP=153.27 M, Params=1.073 MB, latency=20.90 ms.\n",
      "cifar10        train : [loss = 0.002, top1 = 99.98%], test  : [loss = 0.282, top1 = 94.22%]\n",
      "cifar100       FLOP=153.28 M, Params=1.079 MB, latency=19.65 ms.\n",
      "cifar100       train : [loss = 0.015, top1 = 99.90%], valid : [loss = 1.260, top1 = 73.13%], test : [loss = 1.232, top1 = 73.17%]\n",
      "ImageNet16-120 FLOP= 38.33 M, Params=1.081 MB, latency=22.08 ms.\n",
      "ImageNet16-120 train : [loss = 1.044, top1 = 70.80%], valid : [loss = 2.252, top1 = 46.32%], test : [loss = 2.247, top1 = 46.48%]\n"
     ]
    }
   ],
   "source": [
    "#def main(xargs):\n",
    "xargs=args\n",
    "assert torch.cuda.is_available(), 'CUDA is not available.'\n",
    "torch.backends.cudnn.enabled   = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.set_num_threads( xargs.workers )\n",
    "prepare_seed(xargs.rand_seed)\n",
    "logger = prepare_logger(args)\n",
    "\n",
    "train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n",
    "if xargs.dataset == 'cifar10' or xargs.dataset == 'cifar100':\n",
    "    split_Fpath = '/home/jiahzhao/Data/NAS-Projects-master/configs/nas-benchmark/cifar-split.txt'\n",
    "    cifar_split = load_config(split_Fpath, None, None)\n",
    "    train_split, valid_split = cifar_split.train, cifar_split.valid\n",
    "    logger.log('Load split file from {:}'.format(split_Fpath))\n",
    "elif xargs.dataset.startswith('ImageNet16'):\n",
    "    split_Fpath = 'configs/nas-benchmark/{:}-split.txt'.format(xargs.dataset)\n",
    "    imagenet16_split = load_config(split_Fpath, None, None)\n",
    "    train_split, valid_split = imagenet16_split.train, imagenet16_split.valid\n",
    "    logger.log('Load split file from {:}'.format(split_Fpath))\n",
    "else:\n",
    "    raise ValueError('invalid dataset : {:}'.format(xargs.dataset))\n",
    "  #config_path = 'configs/nas-benchmark/algos/GDAS.config'\n",
    "config = load_config(xargs.config_path, {'class_num': class_num, 'xshape': xshape}, logger)\n",
    "\n",
    "train_data_v2 = deepcopy(train_data)\n",
    "train_data_v2.transform = valid_data.transform\n",
    "valid_data    = train_data_v2\n",
    "search_data   = SearchDataset(xargs.dataset, train_data, train_split, valid_split)\n",
    "# data loader\n",
    "search_loader = torch.utils.data.DataLoader(search_data, batch_size=config.batch_size, shuffle=True , num_workers=xargs.workers, pin_memory=True)\n",
    "valid_loader  = torch.utils.data.DataLoader(valid_data, batch_size=config.batch_size, sampler=torch.utils.data.sampler.SubsetRandomSampler(valid_split), num_workers=xargs.workers, pin_memory=True)\n",
    "\n",
    "\n",
    "logger.log('||||||| {:10s} ||||||| Search-Loader-Num={:}, batch size={:}'.format(xargs.dataset, len(search_loader), config.batch_size))\n",
    "logger.log('||||||| {:10s} ||||||| Config={:}'.format(xargs.dataset, config))\n",
    "\n",
    "search_space = get_search_spaces('cell', xargs.search_space_name)\n",
    "model_config = dict2config({'name': 'EENAS', 'C': xargs.channel, 'N': xargs.num_cells,\n",
    "                          'max_nodes': xargs.max_nodes, 'num_classes': class_num,\n",
    "                          'space'    : search_space,\n",
    "                          'affine'   : False, 'track_running_stats': bool(xargs.track_running_stats)}, None)\n",
    "search_model = get_cell_based_tiny_net(model_config)\n",
    "#from models.cell_searchs.search_model_gdas import TinyNetworkGDAS as get_cell_based_tiny_net\n",
    "#search_model = get_cell_based_tiny_net(xargs.channel,xargs.num_cells,xargs.max_nodes,class_num,search_space, False,bool(xargs.track_running_stats))\n",
    "logger.log('search-model :\\n{:}'.format(search_model))\n",
    "\n",
    "w_optimizer, w_scheduler, criterion = get_optim_scheduler(search_model.get_weights(), config)\n",
    "a_optimizer = torch.optim.Adam(search_model.get_alphas(), lr=xargs.arch_learning_rate, betas=(0.5, 0.999), weight_decay=xargs.arch_weight_decay)\n",
    "logger.log('w-optimizer : {:}'.format(w_optimizer))\n",
    "logger.log('a-optimizer : {:}'.format(a_optimizer))\n",
    "logger.log('w-scheduler : {:}'.format(w_scheduler))\n",
    "logger.log('criterion   : {:}'.format(criterion))\n",
    "#flop, param  = get_model_infos(search_model, xshape)\n",
    "#logger.log('{:}'.format(search_model))\n",
    "#logger.log('FLOP = {:.2f} M, Params = {:.2f} MB'.format(flop, param))\n",
    "logger.log('search-space : {:}'.format(search_space))\n",
    "if xargs.arch_nas_dataset is None:\n",
    "    api = None\n",
    "else:\n",
    "    api = API(xargs.arch_nas_dataset)\n",
    "logger.log('{:} create API = {:} done'.format(time_string(), api))\n",
    "\n",
    "last_info, model_base_path, model_best_path = logger.path('info'), logger.path('model'), logger.path('best')\n",
    "network, criterion = torch.nn.DataParallel(search_model,device_ids=[0]).cuda(), criterion.cuda()\n",
    "\n",
    "if last_info.exists(): # automatically resume from previous checkpoint\n",
    "    logger.log(\"=> loading checkpoint of the last-info '{:}' start\".format(last_info))\n",
    "    last_info   = torch.load(last_info)\n",
    "    start_epoch = last_info['epoch']\n",
    "    checkpoint  = torch.load(last_info['last_checkpoint'])\n",
    "    genotypes   = checkpoint['genotypes']\n",
    "    valid_accuracies = checkpoint['valid_accuracies']\n",
    "    search_model.load_state_dict( checkpoint['search_model'] )\n",
    "    w_scheduler.load_state_dict ( checkpoint['w_scheduler'] )\n",
    "    w_optimizer.load_state_dict ( checkpoint['w_optimizer'] )\n",
    "    a_optimizer.load_state_dict ( checkpoint['a_optimizer'] )\n",
    "    logger.log(\"=> loading checkpoint of the last-info '{:}' start with {:}-th epoch.\".format(last_info, start_epoch))\n",
    "else:\n",
    "    logger.log(\"=> do not find the last-info file : {:}\".format(last_info))\n",
    "    start_epoch, valid_accuracies, genotypes = 0, {'best': -1}, {}\n",
    "\n",
    "  # start training\n",
    "start_time, search_time, epoch_time, total_epoch = time.time(), AverageMeter(), AverageMeter(), config.epochs + config.warmup\n",
    "arch_archive=[]\n",
    "for epoch in range(start_epoch, total_epoch):\n",
    "    w_scheduler.update(epoch, 0.0)\n",
    "    need_time = 'Time Left: {:}'.format( convert_secs2time(epoch_time.val * (total_epoch-epoch), True) )\n",
    "    epoch_str = '{:03d}-{:03d}'.format(epoch, total_epoch)\n",
    "    search_model.set_tau( xargs.tau_max - (xargs.tau_max-xargs.tau_min) * epoch / (total_epoch-1) )\n",
    "    logger.log('\\n[Search the {:}-th epoch] {:}, tau={:}, LR={:}'.format(epoch_str, need_time, search_model.get_tau(), min(w_scheduler.get_lr())))\n",
    "    \n",
    "    exp_ratio=10########################define the exporation ratio\n",
    "    forg_ratio=0.5##########################################define the forgetting ratio\n",
    "    ex_ep_ratio=((epoch/total_epoch)*2-1)*exp_ratio\n",
    "\n",
    "    multi_model_ratio=0.5\n",
    "    \n",
    "    \n",
    "    search_w_loss, search_w_top1, search_w_top5, valid_a_loss , valid_a_top1 , valid_a_top5, arch_archive \\\n",
    "              = search_func(search_loader, network, criterion, w_scheduler, w_optimizer, a_optimizer, epoch_str, xargs.print_freq, logger,arch_archive,ex_ep_ratio,multi_model_ratio)\n",
    "    search_time.update(time.time() - start_time)\n",
    "    logger.log('[{:}] searching : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%, time-cost={:.1f} s'.format(epoch_str, search_w_loss, search_w_top1, search_w_top5, search_time.sum))\n",
    "    logger.log('[{:}] evaluate  : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%'.format(epoch_str, valid_a_loss , valid_a_top1 , valid_a_top5 ))\n",
    "    # check the best accuracy\n",
    "    valid_accuracies[epoch] = valid_a_top1\n",
    "    if valid_a_top1 > valid_accuracies['best']:\n",
    "        valid_accuracies['best'] = valid_a_top1\n",
    "        genotypes['best']        = search_model.genotype()\n",
    "        find_best = True\n",
    "    else: find_best = False\n",
    "\n",
    "    genotypes[epoch] = search_model.genotype()\n",
    "    logger.log('<<<--->>> The {:}-th epoch : {:}'.format(epoch_str, genotypes[epoch]))\n",
    "    # save checkpoint\n",
    "    save_path = save_checkpoint({'epoch' : epoch + 1,\n",
    "                'args'  : deepcopy(xargs),\n",
    "                'search_model': search_model.state_dict(),\n",
    "                'w_optimizer' : w_optimizer.state_dict(),\n",
    "                'a_optimizer' : a_optimizer.state_dict(),\n",
    "                'w_scheduler' : w_scheduler.state_dict(),\n",
    "                'genotypes'   : genotypes,\n",
    "                'valid_accuracies' : valid_accuracies},\n",
    "                model_base_path, logger)\n",
    "    last_info = save_checkpoint({\n",
    "          'epoch': epoch + 1,\n",
    "          'args' : deepcopy(args),\n",
    "          'last_checkpoint': save_path,\n",
    "          }, logger.path('info'), logger)\n",
    "    if find_best:\n",
    "        logger.log('<<<--->>> The {:}-th epoch : find the highest validation accuracy : {:.2f}%.'.format(epoch_str, valid_a_top1))\n",
    "        copy_checkpoint(model_base_path, model_best_path, logger)\n",
    "    with torch.no_grad():\n",
    "        logger.log('arch-parameters :\\n{:}'.format( nn.functional.softmax(search_model.arch_parameters, dim=-1).cpu() ))\n",
    "    if api is not None: logger.log('{:}'.format(api.query_by_arch( genotypes[epoch] )))\n",
    "    # measure elapsed time\n",
    "    epoch_time.update(time.time() - start_time)\n",
    "    start_time = time.time()\n",
    "\n",
    "logger.log('\\n' + '-'*100)\n",
    "  # check the performance from the architecture dataset\n",
    "logger.log('EENAS : run {:} epochs, cost {:.1f} s, last-geno is {:}.'.format(total_epoch, search_time.sum, genotypes[total_epoch-1]))\n",
    "if api is not None: logger.log('{:}'.format( api.query_by_arch(genotypes[total_epoch-1]) ))\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
